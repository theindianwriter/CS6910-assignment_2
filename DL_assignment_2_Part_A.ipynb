{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL assignment 2 Part A.ipynb",
      "provenance": [],
      "mount_file_id": "1yBwQxhZYw9UwQKB6m5B6UEjQDTjhCM-l",
      "authorship_tag": "ABX9TyMVuIHSllTXoO5YaPpXYv32",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theindianwriter/CS6910-assignment_2/blob/main/DL_assignment_2_Part_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N1GggAe4er0"
      },
      "source": [
        "import numpy as np #for linear algebra operations\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image #for preprocessing the images"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vIoRdcUHv4T"
      },
      "source": [
        "# PyTorch libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBY4eeZl7YAE"
      },
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-Hsrl6xvjPG"
      },
      "source": [
        "#enabling gpu \n",
        "device = \"cpu\"\n",
        "if (torch.cuda.is_available()):\n",
        "    device = \"cuda\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VltGV369bGI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbb677f-15b0-4564-b113-579262dafffa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh4zod8Yu57S"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/nature_12K.zip\" -d \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnT3TkaIuWMh"
      },
      "source": [
        "training_folder_path = \"/content/drive/MyDrive/inaturalist_12K/train\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z77LxCosR_K",
        "outputId": "7dedd357-1f07-4ed3-f135-aaefd290d3ab"
      },
      "source": [
        "#list down all the classes present in the dataset\n",
        "classes = sorted([folder_name  for folder_name in os.listdir(training_folder_path) if not folder_name.startswith('.')])\n",
        "print(classes)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Q1gzto7hcc"
      },
      "source": [
        "# function to resize image\n",
        "def resize_image(src_image, size=(128,128), bg_color=\"white\"): \n",
        "    #creating a thumbnail of the image of the given size preserving the aspect ratio\n",
        "    src_image.thumbnail(size,Image.ANTIALIAS)\n",
        "    #creating a background image \n",
        "    new_image = Image.new(\"RGB\", size, bg_color)\n",
        "    #pasting the src image into it \n",
        "    new_image.paste(src_image, (int((size[0] - src_image.size[0]) / 2), int((size[1] - src_image.size[1]) / 2)))\n",
        "    return new_image"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT3LCHBVu9Zp"
      },
      "source": [
        "new_training_folder_path = \"../Natural_Dataset/train\""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcNbZ1vvRNsr",
        "outputId": "142484a9-1ec9-45dc-b6c0-f665cbff1cfd"
      },
      "source": [
        "image_size = (128,128)\n",
        "\n",
        "if os.path.exists(new_training_folder_path):\n",
        "    #shutil.rmtree(new_training_folder_path)\n",
        "\n",
        "for root,folders,_ in os.walk(training_folder_path):\n",
        "    for folder in folders:\n",
        "        print(\"resizing the images and saving for the folder \",folder)\n",
        "        new_folder = os.path.join(new_training_folder_path,folder)\n",
        "\n",
        "        if not os.path.exists(new_folder):\n",
        "            os.makedirs(new_folder)\n",
        "        \n",
        "        file_names = os.listdir(os.path.join(root,folder))\n",
        "        \n",
        "        for file_name in file_names:\n",
        "            if file_name.startswith('.'):\n",
        "                continue\n",
        "            file_path = os.path.join(root,folder,file_name)\n",
        "            image = Image.open(file_path)\n",
        "            resized_image = resize_image(image,image_size,\"black\")\n",
        "            save_as = os.path.join(new_folder,file_name)\n",
        "            resized_image.save(save_as)\n",
        "\n",
        "print(\"resizing and saving done\")\n",
        "\n",
        "        \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resizing the images and saving for the folder  Reptilia\n",
            "resizing the images and saving for the folder  Mammalia\n",
            "resizing the images and saving for the folder  Arachnida\n",
            "resizing the images and saving for the folder  Plantae\n",
            "resizing the images and saving for the folder  Aves\n",
            "resizing the images and saving for the folder  Amphibia\n",
            "resizing the images and saving for the folder  Insecta\n",
            "resizing the images and saving for the folder  Animalia\n",
            "resizing the images and saving for the folder  Mollusca\n",
            "resizing the images and saving for the folder  Fungi\n",
            "resizing and saving done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckAjSb-Prbw9"
      },
      "source": [
        "mean = [0.5,0.5,0.5]\n",
        "std = [0.5,0.5,0.5]\n",
        "\n",
        "def load_dataset(dataset_path,data_augmentation = False,batch_size = 50):\n",
        "    if data_augmentation:\n",
        "        transformation = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(0.5),\n",
        "            transforms.RandomVerticalFlip(0.3),\n",
        "            transforms.ToTensor(),\n",
        "        # Normalize the pixel values (in R, G, and B channels)\n",
        "            transforms.Normalize(mean=mean, std=std)\n",
        "        ])\n",
        "    else:\n",
        "        transformation = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean,std = std)                               \n",
        "        ])\n",
        "\n",
        "    full_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=dataset_path,\n",
        "        transform=transformation\n",
        "    )\n",
        "\n",
        "    train_size = int(0.9 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=0,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=0,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return train_loader,test_loader"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh2IRxw8v5TR",
        "outputId": "81022cd1-b4a2-43fc-a2bc-df15be7f31be"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzGaDYke3z3B"
      },
      "source": [
        "class Network(nn.Module):\n",
        "\n",
        "    def __init__(self,num_of_classes,filters,filter_size,activation_fn,stride_len = 1,padding_len = 1,max_pool_kernel_size = 2,max_pool_stride_len = 2,dropdout_ratio = 0.0,dense_neuron_size = 20000,img_size = (128,128)):\n",
        "        super(Network,self).__init__()\n",
        "\n",
        "        self.activation_fn = activation_fn\n",
        "        \n",
        "\n",
        "        Out_dim_H = img_size[0]\n",
        "        Out_dim_W = img_size[1]\n",
        "\n",
        "        for F in filter_size:\n",
        "            Out_dim_H =  int(((Out_dim_H - F + 2*padding_len)/stride_len)) + 1\n",
        "            Out_dim_W =  int(((Out_dim_W - F + 2*padding_len)/stride_len)) + 1\n",
        "            Out_dim_H =  int(((Out_dim_H - max_pool_kernel_size)/max_pool_stride_len))+ 1\n",
        "            Out_dim_W =  int(((Out_dim_W - max_pool_kernel_size)/max_pool_stride_len)) + 1\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,out_channels = filters[0],kernel_size = filter_size[0],stride = stride_len,padding = padding_len)\n",
        "        self.conv2 = nn.Conv2d(in_channels = filters[0],out_channels = filters[1],kernel_size = filter_size[1],stride = stride_len,padding = padding_len)\n",
        "        self.conv3 = nn.Conv2d(in_channels = filters[1],out_channels = filters[2],kernel_size = filter_size[2],stride = stride_len,padding = padding_len)\n",
        "        self.conv4 = nn.Conv2d(in_channels = filters[2],out_channels = filters[3],kernel_size = filter_size[3],stride = stride_len,padding = padding_len)\n",
        "        self.conv5 = nn.Conv2d(in_channels = filters[3],out_channels = filters[4],kernel_size = filter_size[4],stride = stride_len,padding = padding_len)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=max_pool_kernel_size,stride = max_pool_stride_len)\n",
        "\n",
        "        self.drop = nn.Dropout2d(p=dropdout_ratio)\n",
        "\n",
        "\n",
        "        self.post_conv_output_len = Out_dim_H*Out_dim_W*filters[4]\n",
        "        #fully connected layer\n",
        "        self.fc1 = nn.Linear(in_features = Out_dim_H*Out_dim_W*filters[4],out_features = dense_neuron_size)\n",
        "        self.fc2 = nn.Linear(in_features = dense_neuron_size,out_features = num_of_classes)\n",
        "\n",
        "\n",
        "\n",
        "    def perform_activation(self,fn,x):\n",
        "        if fn == 'relu':\n",
        "            return F.relu(x)\n",
        "        elif fn == 'elu':\n",
        "            return F.elu(x)\n",
        "        elif fn == 'leaky_relu':\n",
        "            return F.leaky_relu(x)\n",
        "        elif fn == 'tanh':\n",
        "            return F.tanh(x)\n",
        "        elif fn == 'sigmoid':\n",
        "            return F.sigmoid(x)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.perform_activation(self.activation_fn[0],self.pool(self.conv1(x)))\n",
        "        x = self.perform_activation(self.activation_fn[1],self.pool(self.conv2(x)))\n",
        "        x = self.perform_activation(self.activation_fn[2],self.pool(self.conv3(x)))\n",
        "        x = self.perform_activation(self.activation_fn[3],self.pool(self.conv4(x)))\n",
        "        x = self.perform_activation(self.activation_fn[4],self.pool(self.conv5(x)))\n",
        "\n",
        "        x = F.dropout(self.drop(x), training=self.training)\n",
        "\n",
        "        x = x.view(-1, self.post_conv_output_len)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "            \n",
        "        return torch.log_softmax(x, dim=1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdV_WNLR02JV"
      },
      "source": [
        "def train(model,train_loader,optimizer,epoch,device):\n",
        "\n",
        "    model.train()\n",
        "    training_loss = 0\n",
        "    batch_id = 0\n",
        "    print(\"----------------------IN EPOCH {}--------------------------------\".format(epoch))\n",
        "    for data,target in train_loader:\n",
        "        batch_id += 1\n",
        "        data,target = data.to(device),target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = loss_criteria(output,target)\n",
        "        training_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"avg training loss is {:.6f}\".format(training_loss/batch_id))\n",
        "    return training_loss\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpzIZ4EOknEu"
      },
      "source": [
        "def test(model,test_loader,device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    batch_id = 0\n",
        "    with torch.no_grad():\n",
        "        for data,target in test_loader:\n",
        "            batch_id += 1\n",
        "            data,target = data.to(device),target.to(device)\n",
        "            output = model(data)\n",
        "            loss = loss_criteria(output,target)\n",
        "            test_loss += loss.item()\n",
        "            _,predicted = torch.max(output.data,1)\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "    accuracy = 100*correct/ len(test_loader.dataset)\n",
        "    print(\"avg val loss is {:.6f} and accuracy is {:.2f}%\".format(test_loss/batch_id,accuracy))\n",
        "    return test_loss,accuracy\n",
        "\n",
        "    \n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhCEzU1ZrTOX",
        "outputId": "f228abca-988d-4d0e-8c69-57f5051a8523"
      },
      "source": [
        "\n",
        "model = Network(num_of_classes=10,filters = [16,32,64,128,256],filter_size = [3,3,3,3,3],activation_fn=['relu','relu','relu','relu','relu'],dropdout_ratio = 0.2,dense_neuron_size = 128).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "train_loader,val_loader = load_dataset(new_training_folder_path,True,50)\n",
        "epochs = 10\n",
        "print('Training on', device)\n",
        "for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, train_loader, optimizer,epoch,device)\n",
        "        test_loss = test(model, val_loader,device)\n",
        "        "
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on cuda\n",
            "----------------------IN EPOCH 1--------------------------------\n",
            "avg training loss is 2.303337\n",
            "avg val loss is 2.299310 and accuracy is 12.70%\n",
            "----------------------IN EPOCH 2--------------------------------\n",
            "avg training loss is 2.299962\n",
            "avg val loss is 2.286598 and accuracy is 11.70%\n",
            "----------------------IN EPOCH 3--------------------------------\n",
            "avg training loss is 2.288812\n",
            "avg val loss is 2.269110 and accuracy is 14.20%\n",
            "----------------------IN EPOCH 4--------------------------------\n",
            "avg training loss is 2.301489\n",
            "avg val loss is 2.305411 and accuracy is 8.90%\n",
            "----------------------IN EPOCH 5--------------------------------\n",
            "avg training loss is 2.295550\n",
            "avg val loss is 2.285270 and accuracy is 13.00%\n",
            "----------------------IN EPOCH 6--------------------------------\n",
            "avg training loss is 2.274202\n",
            "avg val loss is 2.267018 and accuracy is 14.30%\n",
            "----------------------IN EPOCH 7--------------------------------\n",
            "avg training loss is 2.254074\n",
            "avg val loss is 2.232807 and accuracy is 17.20%\n",
            "----------------------IN EPOCH 8--------------------------------\n",
            "avg training loss is 2.236030\n",
            "avg val loss is 2.229387 and accuracy is 16.10%\n",
            "----------------------IN EPOCH 9--------------------------------\n",
            "avg training loss is 2.220493\n",
            "avg val loss is 2.223363 and accuracy is 18.60%\n",
            "----------------------IN EPOCH 10--------------------------------\n",
            "avg training loss is 2.214806\n",
            "avg val loss is 2.221860 and accuracy is 16.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpjCFt8b7wHk"
      },
      "source": [
        "defaults = dict(\n",
        "  num_of_filters = 32,\n",
        "  filter_size = 3,\n",
        "  rate = 2\n",
        "  activation_fn='relu',\n",
        "  dropdout_ratio = 0.3,\n",
        "  dense_neuron_size = 128,\n",
        "  lr = 0.0001\n",
        "  batch_size = 50,\n",
        "  epochs = 10,\n",
        "  data_augmentation = True\n",
        ")\n",
        "\n",
        "wandb.init(project=\"cs6910-assignment2\",config = defaults)\n",
        "config = wandb.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YMo9_Kp8gNY"
      },
      "source": [
        "filters = []\n",
        "filter_size = []\n",
        "activation_fn = []  \n",
        "rate = 1\n",
        "for i in range(5):\n",
        "    activation_fn.append(config.activation_fn)\n",
        "    filter_size.append(config.filter_size)\n",
        "    filters.append(config.num_of_filter*rate)\n",
        "    rate *= config.rate\n",
        "\n",
        "model = Network(num_of_classes=10,filters = filters,filter_size = filter_size,activation_fn=activation_fn,dropdout_ratio = config.dropout_ratio,dense_neuron_size = config.dense_neuron_size,stride_len = 1,padding_len = config.padding_len,max_pool_kernel_size = config.max_pool_kernel_size,max_pool_stride_len = config.max_pool_stride_len).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "train_loader,val_loader = load_dataset(new_training_folder_path,config.data_augmentation,config.batch_size)\n",
        "epochs = config.epochs\n",
        "print('Training on', device)\n",
        "for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, train_loader, optimizer,epoch,device)\n",
        "        val_loss,accuracy = test(model, val_loader,device)\n",
        "        wandb.log({\"epoch\": epoch,\"accuracy\" : accuracy,\"training loss\":train_loss,\"validation loss\": val_loss })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7zGsBMhLds_"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'random', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'lr': {\n",
        "            'values': [0.0001, 0.0005,0.0008]\n",
        "        },\n",
        "        'activation_fn': {\n",
        "            'values': ['relu', 'tanh']\n",
        "        },\n",
        "        'num_of_filters': {\n",
        "            'values' : [32,64]\n",
        "        },\n",
        "        'filter_size' : {\n",
        "            'values' : [3,5]\n",
        "        },\n",
        "        'filter_organization':{\n",
        "            'values': [2,1]\n",
        "        },\n",
        "        'batch_size':{\n",
        "            'values': [100,200]\n",
        "        },\n",
        "        'dropdout_ratio': {\n",
        "            'values': [0.2,0.3,0.4]\n",
        "        },\n",
        "        'dense_neuron_size':{\n",
        "            'values' : [200,100]\n",
        "        },\n",
        "        'data_augmentation':{\n",
        "            'values': [True,False]\n",
        "        },\n",
        "        'epochs':{\n",
        "            'values' : [10,5,15]\n",
        "        },\n",
        "\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVsvX3RrJ6yS"
      },
      "source": [
        "def experiment():\n",
        "    defaults = dict(\n",
        "    num_of_filters = 32,\n",
        "    filter_size = 3,\n",
        "    filter_organization = 2\n",
        "    activation_fn='relu',\n",
        "    dropdout_ratio = 0.03,\n",
        "    dense_neuron_size = 20000,\n",
        "    lr = 0.01\n",
        "    batch_size = 50,\n",
        "    epochs = 10,\n",
        "    data_augmentation = True\n",
        "    )\n",
        "\n",
        "    wandb.init(project=\"cs6910-assignment2\",config = defaults)\n",
        "    config = wandb.config\n",
        "\n",
        "    filters = []\n",
        "    filter_size = []\n",
        "    activation_fn = []  \n",
        "    rate = 1\n",
        "    for i in range(5):\n",
        "        activation_fn.append(config.activation_fn)\n",
        "        filter_size.append(config.filter_size)\n",
        "        filters.append(config.num_of_filter*rate)\n",
        "        rate *= config.filter_organization\n",
        "\n",
        "    model = Network(num_of_classes=10,filters = filters,filter_size = filter_size,activation_fn=activation_fn,dropdout_ratio = config.dropout_ratio,dense_neuron_size = config.dense_neuron_size).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "    loss_criteria = nn.CrossEntropyLoss()\n",
        "    train_loader,val_loader = load_dataset(new_training_folder_path,config.data_augmentation,config.batch_size)\n",
        "    epochs = config.epochs\n",
        "    print('Training on', device)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, train_loader, optimizer,epoch,device)\n",
        "        val_loss,accuracy = test(model, val_loader,device)\n",
        "        wandb.log({\"epoch\": epoch,\"accuracy\" : accuracy,\"training loss\":train_loss,\"validation loss\": val_loss })"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}